# This is a solution of Kaggle machine learning competition for regression using the "House pricing dataset" as an example

## User requirements

<ul>
  <li>Jupyter-notebook</li>
  <li><b>Python libraries</b>: pandas,  sklearn, seaborn, collections, scipy, xgboost, lightgbm </li>
</ul>

## Brief information

<ol>
  <li>
    Solution file: homes_regression.ipynb. Datasets: test.csv, train.csv. Data description - data_description.txt. Regression predictions on test data - answers.csv.
  </li>
  <li>
    This is the solution to a well-known problem from the Kaggle competition. This was my learning task in a machine learning course. Since this is my first project related to data preprocessing, the open solutions of the participants of this competition were also used in the process of solving it.
  </li>
  <li>
    It is necessary to carry out the initial processing of the training data, then determine the most significant features for predicting the value of houses. Then you need to test various models on the input dataset. Based on the most successful model, it was necessary to make predictions for the test data.
  </li>
  <li>
    A grid search was used to find the best model and optimal parameters for this model.
  </li>
</ol>
